{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks in Keras\n",
    "\n",
    "Personal notes on Udacity MLND Deep Learning section.\n",
    "\n",
    "Let's start with a singel hidden layer model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 129\n",
      "Trainable params: 129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28266066312789917, 1.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "\n",
    "# X shape: (num_rows, num_cols)\n",
    "# training data stored as row vectors\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "\n",
    "# y must have an output vector for each input vector\n",
    "y = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
    "\n",
    "\n",
    "'''\n",
    "Create sequential model.\n",
    "This is a wraper to treat the network as a sequence of layers that implements the model interface with\n",
    "methods `compile()`, `fit()`, `evaluate()`... used to train and run the model.\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "'''\n",
    "The Layer class provides common interface for a variety of layers (fully connected, max pool, activation, ...)\n",
    "You can add a layer to a model using the model's `add()` method\n",
    "'''\n",
    "# 1st Layer - Add an input layer of 32 nodes with the same input shape as the training samples in X\n",
    "# you only have to explicitly set the input dimensions for the first layer\n",
    "model.add(Dense(32, input_dim=X.shape[1]))\n",
    "\n",
    "# Add a softmax activation layer\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 2nd Layer - Add a fully connected output layer (1 node)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Add a sigmoid activation layer\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "'''\n",
    "Compiling\n",
    "Call backend (TF), and bind loss function, optimizer, evaluation metric, ...\n",
    "'''\n",
    "#model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "'''\n",
    "See the resulting model architecture\n",
    "'''\n",
    "model.summary()\n",
    "\n",
    "'''\n",
    "Train the model\n",
    "'''\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Stochastic Gradient Descent, specify batches:\n",
    "##model.fit(X_train, y_train, epochs=1000, batch_size=100, verbose=0)\n",
    "\n",
    "'''\n",
    "Evaluate the model\n",
    "'''\n",
    "model.evaluate(X, y) # score = model.evaluate(x_test, y_test, verbose=0) \n",
    "                     # https://github.com/fchollet/keras/blob/master/examples/mnist_mlp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xor quiz\n",
    "\n",
    "Code used in the interface:\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "# Using TensorFlow 1.0.0; use tf.python_io in later versions\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Our data\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]]).astype('float32')\n",
    "y = np.array([[0],[1],[1],[0]]).astype('float32')\n",
    "\n",
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "# Building the model\n",
    "xor = Sequential()\n",
    "\n",
    "# Add required layers\n",
    "xor.add(Dense(8, input_dim=2))\n",
    "xor.add(Activation('tanh'))\n",
    "xor.add(Dense(1))\n",
    "xor.add(Activation('sigmoid'))\n",
    "\n",
    "# Specify loss as \"binary_crossentropy\", optimizer as \"adam\",\n",
    "# and add the accuracy metric\n",
    "xor.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "# Uncomment this line to print the model architecture\n",
    "xor.summary()\n",
    "\n",
    "# Fitting the model\n",
    "history = xor.fit(X, y, nb_epoch=300, verbose=0)\n",
    "\n",
    "# Scoring the model\n",
    "score = xor.evaluate(X, y)\n",
    "print(\"\\nAccuracy: \", score[-1])\n",
    "\n",
    "# Checking the predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(xor.predict_proba(X))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "Using TensorFlow backend.\n",
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to                     \n",
    "====================================================================================================\n",
    "dense_1 (Dense)                  (None, 8)             24          dense_input_1[0][0]              \n",
    "____________________________________________________________________________________________________\n",
    "activation_1 (Activation)        (None, 8)             0           dense_1[0][0]                    \n",
    "____________________________________________________________________________________________________\n",
    "dense_2 (Dense)                  (None, 1)             9           activation_1[0][0]               \n",
    "____________________________________________________________________________________________________\n",
    "activation_2 (Activation)        (None, 1)             0           dense_2[0][0]                    \n",
    "====================================================================================================\n",
    "Total params: 33\n",
    "Trainable params: 33\n",
    "Non-trainable params: 0\n",
    "____________________________________________________________________________________________________\n",
    "\n",
    "4/4 [==============================] - 0s\n",
    "\n",
    "Accuracy:  1.0\n",
    "\n",
    "Predictions:\n",
    "\n",
    "4/4 [==============================] - 0s\n",
    "[[ 0.42648906]\n",
    " [ 0.51158553]\n",
    " [ 0.57282132]\n",
    " [ 0.48525804]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "# Test and training sets\n",
    "\n",
    "(X_train, X_test) = X[50:], X[:50]\n",
    "(y_train, y_test) = y[50:], y[:50]\n",
    "```\n",
    "\n",
    "Underfitting => High bias\n",
    "Overfitting => High variance\n",
    "\n",
    "Go for overfitting and then try to reduce it:\n",
    "\n",
    "1. Stop early  \n",
    "Right number of epochs: plot epochs vs training / testing error [Model Complexity Graph]\n",
    "\n",
    "2. Regularization\n",
    "Large coefficients tend to overfit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 first prediction: 0.880797077978\n",
      "Model 1 second prediction: 0.119202922022\n",
      "Model 2 first prediction: 0.999999997939\n",
      "Model 2 second prediction: 2.06115361819e-09\n"
     ]
    }
   ],
   "source": [
    "# Large coefficient example\n",
    "\n",
    "'''\n",
    "Separate (1,1) and (-1,-1)\n",
    "first model: x_1 + x_2 => w_1=1, w_2=1\n",
    "second model: 10x_1 + 10x_2 => w_1=10, w_2=10\n",
    "'''\n",
    "\n",
    "# apply sigmoid function\n",
    "from scipy.special import expit\n",
    "\n",
    "# Model 1\n",
    "print('Model 1 first prediction:', expit(1+1)) # (1,1) prediction\n",
    "print('Model 1 second prediction:', expit(-1-1)) # (-1,-1) prediction\n",
    "\n",
    "# Model 2\n",
    "print('Model 2 first prediction:', expit(10+10)) # (1,1) prediction\n",
    "print('Model 2 second prediction:', expit(-10-10)) # (-1,-1) prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model is overffiting.\n",
    "\n",
    "To penalize large weights one can add a term in the error function that is the sums of the absolute values of the weights [L1 Regularization], or the sum of the squares of the weights [L2 Regularization], in any case times a constant lambda. \n",
    "\n",
    "L1 yields sparse vectors (small vectors go to 0). Good for feature selection.\n",
    "\n",
    "L2 tries to mantain all the weights homogeneously small. Normally better for training models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
